{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb87d75",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59009ee4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 1: Introduction to ML\n",
    "- **Chapter**: 1\n",
    "- **Topics**:\n",
    "  - What is Machine Learning?\n",
    "  - Why is ML used?\n",
    "  - Types of ML algorithms.\n",
    "  - Challenges in ML\n",
    "- **Videos**:\n",
    "  - Video 1: What is Machine Learning? (20:00)\n",
    "  - Video 2: AI Vs ML Vs DL for Beginners in Hindi (16:02)\n",
    "  - Video 3: Types of Machine Learning for Beginners (27:42)\n",
    "  - Video 4: Batch Machine Learning (11:28)\n",
    "  - Video 5: Online Machine Learning (19:28)\n",
    "  - Video 6: Instance-Based Vs Model-Based Learning (16:44)\n",
    "  - Video 7: Challenges in Machine Learning (23:40)\n",
    "  - Video 8: Application of Machine Learning (29:02)\n",
    "- **Goals**: Understand ML’s definition, purpose, and main categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5003c92c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 2: ML Project Lifecycle and Data Preparation\n",
    "- **Chapter**: 2\n",
    "- **Topics**:\n",
    "  - Steps in a typical ML project (MLDLC).\n",
    "  - Handling, cleaning, and preparing data.\n",
    "  - Basic data concepts (tensors, datasets).\n",
    "- **Videos**:\n",
    "  - Video 9: Machine Learning Development Life Cycle (25:13)\n",
    "  - Video 11: What are Tensors (41:29)\n",
    "  - Video 12: Installing Anaconda For Data Science (37:06)\n",
    "- **Goals**: Learn the ML workflow and data preprocessing basics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef63e65",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 3: Linear Regression\n",
    "- **Chapter**: 4\n",
    "- **Topics**:\n",
    "  - Learning by fitting a model (linear regression).\n",
    "  - Cost functions and optimization.\n",
    "  - Regression metrics (MSE, MAE, RMSE, R²).\n",
    "- **Videos**:\n",
    "  - Video 50: Simple Linear Regression (33:36)\n",
    "  - Video 51: Simple Linear Regression | Mathematical Formulation (53:31)\n",
    "  - Video 52: Regression Metrics (43:56)\n",
    "- **Goals**: Master linear regression and evaluation metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0011f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 4: Multiple and Polynomial Regression\n",
    "- **Chapter**: 4\n",
    "- **Topics**:\n",
    "  - Multiple linear regression.\n",
    "  - Polynomial regression for non-linear data.\n",
    "- **Videos**:\n",
    "  - Video 53: Multiple Linear Regression | Geometric Intuition (20:57)\n",
    "  - Video 54: Multiple Linear Regression | Mathematical Formulation (48:11)\n",
    "  - Video 55: Multiple Linear Regression | Code From Scratch (16:01)\n",
    "  - Video 60: Polynomial Regression (26:46)\n",
    "- **Goals**: Understand extensions of linear models for complex data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473fe72",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 5: Optimization and Regularization\n",
    "- **Chapter**: 4\n",
    "- **Topics**:\n",
    "  - Gradient descent (batch, stochastic, mini-batch).\n",
    "  - Regularized linear models (Ridge, Lasso, ElasticNet).\n",
    "  - Bias/variance trade-off, overfitting, underfitting.\n",
    "- **Videos**:\n",
    "  - Video 56: Gradient Descent From Scratch (1:57:56)\n",
    "  - Video 57: Batch Gradient Descent (1:04:49)\n",
    "  - Video 58: Stochastic Gradient Descent (49:35)\n",
    "  - Video 59: Mini-Batch Gradient Descent (22:10)\n",
    "  - Video 61: Bias Variance Trade-off (8:05)\n",
    "  - Video 62-65: Ridge Regression Series (2:00:58)\n",
    "  - Video 66-67: Lasso Regression (52:47)\n",
    "  - Video 68: ElasticNet Regression (11:41)\n",
    "- **Goals**: Learn optimization techniques and regularization to prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b6884",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 6: Logistic Regression\n",
    "- **Chapter**: 4, 3\n",
    "- **Topics**:\n",
    "  - Logistic regression for classification.\n",
    "  - Sigmoid function, loss functions (binary cross-entropy).\n",
    "  - Classification metrics (accuracy, confusion matrix, precision, recall, F1).\n",
    "- **Videos**:\n",
    "  - Video 69-74: Logistic Regression Series (2:50:49)\n",
    "  - Video 75: Accuracy and Confusion Matrix (34:08)\n",
    "  - Video 76: Precision, Recall and F1 Score (42:42)\n",
    "  - Video 77: Softmax Regression (38:21)\n",
    "  - Video 78: Polynomial Features in Logistic Regression (9:11)\n",
    "  - Video 79: Logistic Regression Hyperparameters (13:07)\n",
    "- **Goals**: Understand classification and evaluation for binary/multiclass problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ca58d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 7: Decision Trees and Random Forests\n",
    "- **Chapter**: 6, 7\n",
    "- **Topics**:\n",
    "  - Decision trees (entropy, Gini impurity, information gain).\n",
    "  - Random forests and ensemble learning (bagging).\n",
    "  - Hyperparameter tuning and feature importance.\n",
    "- **Videos**:\n",
    "  - Video 80: Decision Trees Geometric Intuition (58:29)\n",
    "  - Video 81: Decision Trees - Hyperparameters (27:23)\n",
    "  - Video 82: Regression Trees (35:15)\n",
    "  - Video 83: Decision Tree Visualization (18:36)\n",
    "  - Video 88-90: Bagging Ensemble Series (1:04:40)\n",
    "  - Video 91-94: Random Forest Series (1:11:57)\n",
    "  - Video 95: Hyperparameter Tuning Random Forest (11:44)\n",
    "  - Video 96: OOB Score (6:45)\n",
    "  - Video 97: Feature Importance (27:20)\n",
    "- **Goals**: Master tree-based models and ensemble techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f54d8e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 8: Boosting and Ensemble Methods\n",
    "- **Chapter**: 7\n",
    "- **Topics**:\n",
    "  - Boosting (AdaBoost, Gradient Boosting, XGBoost).\n",
    "  - Stacking and blending ensembles.\n",
    "  - Bagging vs. boosting.\n",
    "- **Videos**:\n",
    "  - Video 98-101: AdaBoost Series (1:16:24)\n",
    "  - Video 102: Bagging Vs Boosting (6:17)\n",
    "  - Video 106-108: Gradient Boosting Series (2:36:44)\n",
    "  - Video 127-130: XGBoost Series (3:40:20)\n",
    "  - Video 109: Stacking and Blending Ensembles (35:20)\n",
    "- **Goals**: Understand advanced ensemble methods for improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86932d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 9: Unsupervised Learning - Clustering\n",
    "- **Chapter**: 9\n",
    "- **Topics**:\n",
    "  - Clustering (K-Means, Hierarchical, DBSCAN).\n",
    "  - Density estimation and anomaly detection.\n",
    "- **Videos**:\n",
    "  - Video 103-105: K-Means Clustering Series (1:16:55)\n",
    "  - Video 110: Agglomerative Hierarchical Clustering (37:23)\n",
    "  - Video 131: DBSCAN Clustering (34:16)\n",
    "- **Goals**: Learn unsupervised techniques for grouping and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734819f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 10: K-Nearest Neighbors and Naive Bayes\n",
    "- **Chapter**: 3\n",
    "- **Topics**:\n",
    "  - K-Nearest Neighbors (KNN) for classification/regression.\n",
    "  - Naive Bayes classifier and probability foundations.\n",
    "- **Videos**:\n",
    "  - Video 111: What is K Nearest Neighbors? (52:01)\n",
    "  - Video 118-126: Naive Bayes Classifier Series (1:29:35)\n",
    "- **Goals**: Understand instance-based and probabilistic ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae61141",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 11: Support Vector Machines\n",
    "- **Chapter**: 5\n",
    "- **Topics**:\n",
    "  - Support Vector Machines (hard/soft margin, kernel trick).\n",
    "  - Assumptions of linear regression (for context).\n",
    "- **Videos**:\n",
    "  - Video 112: Assumptions of Linear Regression (17:38)\n",
    "  - Video 113-117: Support Vector Machines Series (1:14:46)\n",
    "- **Goals**: Master SVMs for complex classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff34e2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 12: Advanced Topics and Practical Considerations\n",
    "- **Chapter**: 3, 2, 9\n",
    "- **Topics**:\n",
    "  - Handling imbalanced data (SMOTE, undersampling, oversampling).\n",
    "  - Hyperparameter tuning (GridSearchCV, RandomizedSearchCV, Optuna).\n",
    "  - ROC-AUC and advanced metrics.\n",
    "  - Challenges in ML (curse of dimensionality, overfitting).\n",
    "- **Videos**:\n",
    "  - Video 132: Imbalanced Data in Machine Learning (57:17)\n",
    "  - Video 133: Hyperparameter Tuning using Optuna (59:23)\n",
    "  - Video 134: ROC Curve in Machine Learning (1:11:15)\n",
    "  - Video 7: Challenges in Machine Learning (23:40)\n",
    "- **Goals**: Address real-world ML challenges and optimize models."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
